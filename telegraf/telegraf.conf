# Telegraf Configuration for Home IOT SCADA Stack
# This configuration collects syslog data from network devices and sends it to InfluxDB
#
# IMPORTANT: This file must be mounted into the Telegraf container at /etc/telegraf/telegraf.conf
# Example volume mount:
#   volumes:
#     - ./telegraf/telegraf.conf:/etc/telegraf/telegraf.conf:Z
#
# The :Z label is required for SELinux systems (like openSUSE Leap Micro) to set proper context.

[agent]
  ## Default data collection interval for all inputs
  interval = "10s"
  
  ## Rounds collection interval to 'interval'
  round_interval = true
  
  ## Telegraf will send metrics to outputs in batches of at most
  ## metric_batch_size metrics.
  metric_batch_size = 1000
  
  ## Maximum number of unwritten metrics per output.
  metric_buffer_limit = 10000
  
  ## Collection jitter is used to jitter the collection by a random amount.
  collection_jitter = "0s"
  
  ## Default flushing interval for all outputs.
  flush_interval = "10s"
  
  ## Jitter the flush interval by a random amount.
  flush_jitter = "0s"
  
  ## Precision of the timestamps (ns, us, ms, s).
  precision = "0s"
  
  ## Override default hostname, if empty use os.Hostname()
  hostname = ""
  
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = false

###############################################################################
#                            OUTPUT PLUGINS                                   #
###############################################################################

# Output to InfluxDB v2.x
[[outputs.influxdb_v2]]
  ## The URLs of the InfluxDB cluster nodes.
  ## Use the service name from compose.yml for internal DNS resolution.
  ## Multiple urls can be specified as part of the same cluster.
  urls = ["http://influxdb:8086"]
  
  ## Token for authentication.
  ## REQUIRED: Set the INFLUX_TOKEN environment variable in your secrets.env file
  ## or in the compose.yml environment section. This should be the same as
  ## INFLUXDB_ADMIN_TOKEN from your secrets.env.
  ##
  ## Example in secrets.env:
  ##   INFLUXDB_ADMIN_TOKEN=your_secure_influxdb_admin_token_here
  ##
  ## In compose.yml, pass it to Telegraf:
  ##   environment:
  ##     - INFLUX_TOKEN=${INFLUXDB_ADMIN_TOKEN}
  token = "${INFLUX_TOKEN}"
  
  ## Organization is the name of the organization you want to write to.
  ## REQUIRED: Set the INFLUX_ORG environment variable.
  ## This should match INFLUXDB_ORG from your secrets.env.
  organization = "${INFLUX_ORG}"
  
  ## Destination bucket to write into.
  ## REQUIRED: Set the INFLUX_BUCKET environment variable.
  ## This should match INFLUXDB_BUCKET from your secrets.env.
  bucket = "${INFLUX_BUCKET}"
  
  ## The value of this tag will be used to determine the bucket.
  ## If this tag is not set the 'bucket' option is used as the default.
  # bucket_tag = ""
  
  ## If true, the bucket tag will not be added to the metric.
  # exclude_bucket_tag = false
  
  ## Timeout for HTTP messages.
  timeout = "5s"
  
  ## HTTP User-Agent
  # user_agent = "telegraf"
  
  ## Additional HTTP headers
  # http_headers = {"X-Special-Header" = "Special-Value"}
  
  ## HTTP Proxy override, if unset values from the standard proxy environment
  ## variables are consulted to determine which proxy, if any, should be used.
  # http_proxy = "http://corporate.proxy:3128"
  
  ## Optional TLS Config for use on HTTP connections.
  # tls_ca = "/etc/telegraf/ca.pem"
  # tls_cert = "/etc/telegraf/cert.pem"
  # tls_key = "/etc/telegraf/key.pem"
  ## Use TLS but skip chain & host verification
  # insecure_skip_verify = false
  
  ## Content-Encoding for write request body, can be set to "gzip" to
  ## compress body or "identity" to apply no encoding.
  # content_encoding = "gzip"
  
  ## Enable or disable uint support for writing uints influxdb 2.0.
  # influx_uint_support = false

###############################################################################
#                            INPUT PLUGINS                                    #
###############################################################################

# Syslog listener for network device logs
# This input plugin listens for syslog messages from network devices such as
# routers, switches, firewalls, and other infrastructure equipment.
[[inputs.syslog]]
  ## Protocol: tcp, udp, or unix
  ## UDP is the most common protocol for syslog from network devices.
  ## TCP provides reliability but requires device support.
  server = "udp://:514"
  
  ## Maximum number of concurrent connections (for TCP only)
  ## Uncomment if using TCP protocol
  # max_connections = 1024
  
  ## Read timeout (for TCP only)
  ## Uncomment if using TCP protocol
  # read_timeout = "5s"
  
  ## Whether to parse in best effort mode or not
  ## If true, will attempt to parse any syslog message format, even if malformed.
  ## Recommended for compatibility with various network device syslog implementations.
  best_effort = true
  
  ## Syslog parser configuration
  ## Supported syslog standards: RFC3164 (BSD syslog), RFC5424 (new syslog), RFC6587 (syslog over TCP)
  ## Set to "automatic" to auto-detect the format, or specify explicitly for better performance.
  # syslog_standard = "RFC5424"
  
  ## Character to trim from the hostname (for RFC3164 only)
  ## Some devices may prefix hostname with specific characters
  # trim_hostname_char = ""

# OPTIONAL: Uncomment below to collect system metrics from the Telegraf container itself
# This can be useful for monitoring the health and performance of the Telegraf service.

# [[inputs.cpu]]
#   ## Whether to report per-cpu stats or not
#   percpu = true
#   
#   ## Whether to report total system cpu stats or not
#   totalcpu = true
#   
#   ## If true, collect raw CPU time metrics.
#   collect_cpu_time = false
#   
#   ## If true, compute and report the sum of all non-idle CPU states.
#   report_active = false

# [[inputs.disk]]
#   ## Mountpoints to include/exclude (supports wildcards)
#   ## Ignore common temporary and virtual filesystems
#   ignore_fs = ["tmpfs", "devtmpfs", "devfs", "iso9660", "overlay", "aufs", "squashfs"]

# [[inputs.mem]]
#   ## No configuration required for basic memory metrics

# [[inputs.net]]
#   ## Interface prefixes to include/exclude (supports wildcards)
#   # interfaces = ["eth*", "en*"]

# [[inputs.system]]
#   ## No configuration required for basic system metrics (load, uptime, etc.)

# OPTIONAL: Uncomment below to collect SNMP metrics from network devices
# Requires SNMP to be enabled on your network devices and community strings or v3 credentials.

# [[inputs.snmp]]
#   ## Agent addresses to retrieve values from
#   ## Format: PROTOCOL://ADDRESS:PORT
#   ## Examples:
#   ##   udp://192.168.1.1:161
#   ##   tcp://192.168.1.1:161
#   agents = ["udp://192.168.1.1:161"]
#   
#   ## SNMP version (1, 2, or 3)
#   version = 2
#   
#   ## SNMP community string (for v1 and v2)
#   community = "public"
#   
#   ## Measurement name
#   name = "snmp"
#   
#   ## SNMP fields to collect
#   ## Example: Interface statistics
#   [[inputs.snmp.field]]
#     name = "hostname"
#     oid = "RFC1213-MIB::sysName.0"
#     is_tag = true
#   
#   [[inputs.snmp.field]]
#     name = "uptime"
#     oid = "DISMAN-EVENT-MIB::sysUpTimeInstance"
#   
#   ## Add more fields as needed based on your device MIBs

###############################################################################
#                         PROCESSOR PLUGINS                                   #
###############################################################################

# OPTIONAL: Add processors to transform data before output
# Examples: filtering, renaming, format conversions

# [[processors.enum]]
#   ## Rename field values
#   [[processors.enum.mapping]]
#     field = "status"
#     [processors.enum.mapping.value_mappings]
#       1 = "OK"
#       2 = "Warning"
#       3 = "Critical"

# [[processors.regex]]
#   ## Apply regex transformations to field values
#   [[processors.regex.fields]]
#     key = "message"
#     pattern = "^(.{50}).*"
#     replacement = "${1}..."

###############################################################################
#                         AGGREGATOR PLUGINS                                  #
###############################################################################

# OPTIONAL: Add aggregators to compute statistics over metrics

# [[aggregators.basicstats]]
#   ## The period on which to flush & clear each aggregator.
#   period = "30s"
#   
#   ## Configures which basic stats to push as fields
#   stats = ["count", "min", "max", "mean", "stdev", "s2", "sum"]
